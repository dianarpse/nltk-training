{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iYPp0Vf-3swK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OClnix_z3zg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SvzneyMZ32aG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = load_iris().data\n",
        "y= load_iris().target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ft3_x1Jn4N9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "2bd274f9-5906-4936-b375-7e6aff9bcf19"
      },
      "cell_type": "code",
      "source": [
        "x[:10], y[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "nmtt_cPI6HlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9bd263cc-b97c-4b10-e6a0-25910dd9c292"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.unique(y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "UUX0zqQK4TDu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#[batch_size ,4]\n",
        "input_features = tf.placeholder(dtype = tf.float32, shape=[None, 4])\n",
        "\n",
        "#[batch_size ,3]\n",
        "input_labels = tf.placeholder(dtype = tf.float32, shape=[None,3])\n",
        "\n",
        "#[4,3]\n",
        "weights = tf.Variable(tf.random_normal(shape=[4, 3]))\n",
        "#[3]\n",
        "biases = tf.Variable(tf.random_normal(shape=[3]))\n",
        "\n",
        "##[batch_size ,4] * [4,3] = #[batch_size ,3]\n",
        "##[batch_size ,3] + [3] = #[batch_size ,3]\n",
        "linear_model = tf.add(tf.matmul(input_features, weights), biases)\n",
        "\n",
        "#average(wx+b -y) **2\n",
        "\n",
        "loss=tf.reduce_mean(tf.square(linear_model - input_labels))\n",
        "\n",
        "train_op =tf.train.GradientDescentOptimizer(learning_rate =0.001).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2mqfGtjV-1EJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n6zON5CU-0Sr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHlz5Ciz-XKG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size,features,labels):\n",
        "  indices = np.arange(start=0,stop = features.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "  indices = indices[:batch_size]\n",
        "  return features[indices],labels[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xtrym0I-aJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "9fab746c-b247-430a-fe5b-4bbdd2ecc94e"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "for epoch in range(10):\n",
        "  for index in range(int(x.shape[0] / batch_size)):\n",
        "    mini_batch_x, mini_batch_y = next_batch(batch_size = batch_size,features = x , labels = y)\n",
        "    \n",
        "    from keras.utils import to_categorical\n",
        "    mini_batch_y = to_categorical(mini_batch_y)\n",
        "    _, train_loss = sess.run([train_op,loss], feed_dict ={input_features:mini_batch_x, input_labels:mini_batch_y})\n",
        "  print('Epoch{}, loss: {}'.format(epoch,train_loss))\n",
        "    "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch0, loss: 23.097190856933594\n",
            "Epoch1, loss: 10.679377555847168\n",
            "Epoch2, loss: 6.978781223297119\n",
            "Epoch3, loss: 3.7844126224517822\n",
            "Epoch4, loss: 2.7340633869171143\n",
            "Epoch5, loss: 2.0225718021392822\n",
            "Epoch6, loss: 2.087045907974243\n",
            "Epoch7, loss: 1.594417929649353\n",
            "Epoch8, loss: 2.0094645023345947\n",
            "Epoch9, loss: 2.2436673641204834\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}